{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9629fe3-32f6-4d47-9b02-185a834cb34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"VARIATIONAL AUTOENCODER FOR STYLE TRANSFER\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65f2fc-c5af-42b3-8404-c93e51cdb18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969a90b-fc1e-4461-b976-4de57272eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LOAD IMAGES to ARRAY images_np\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c254ebb-aaad-43db-b9c0-cbadae74421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Piet_Mondrian128x128.npy\n",
    "#Gustav_Klimt128x128.npy\n",
    "#Henri_Matisse128x128.npy \n",
    "#Jackson_Pollock128x128.npy \n",
    "#Pablo_Picasso128x128.npy\n",
    "#Amedeo_Modigliani_faces128x128.npy\n",
    "#Vasiliy_Kandinskiy_geometric128x128.npy\n",
    "#Pablo_Picasso_faces128x128.npy\n",
    "#STUDENT_PHOTOS128x128.npy\n",
    "#Piet_Mondrian_geometric128x128.npy\n",
    "#FinalLightPaintingData128x128.npy\n",
    "    \n",
    "    \n",
    "data1 = np.load('Amedeo_Modigliani_faces128x128.npy')\n",
    "\n",
    "data2 = np.load('Abstractblue.npy') \n",
    "\n",
    "data3 = np.load('Marc_Chagall128x128.npy') \n",
    "\n",
    "data4 = np.load('Monet128x128.npy') \n",
    "\n",
    "data5 = np.load('Henri_de_Toulouse-Lautrec128x128.npy')\n",
    "\n",
    "data6 = np.load('Sidewalk128x128.npy')\n",
    "data7 = np.load('Tunnel128x128.npy') \n",
    "data8 = np.load('Butterfly128x128.npy') \n",
    "\n",
    "data9 = np.load('Amedeo_Modigliani_faces128x128.npy')\n",
    "data10 =np.load('FinalLightPaintingData128x128.npy')\n",
    "\n",
    "data11 = np.load('Sidewalk128x128.npy')\n",
    "data12 = np.load('Tunnel128x128.npy') \n",
    "data13 = np.load('Butterfly128x128.npy') \n",
    "data14 = np.load('Piet_Mondrian_geometric128x128.npy')\n",
    "\n",
    "data15 = np.load('Gabbiano_portrait128x128.npy')\n",
    "\n",
    "data16 = np.load('Gabbiano_Hamiltonian_chaos128x128.npy')\n",
    "\n",
    "data17 = np.load('STUDENT_PHOTOS128x128.npy')\n",
    "\n",
    "data18 = np.load('Monet paintings.npy') \n",
    "\n",
    "\n",
    "#combine sets\n",
    "#images_np = np.concatenate((data1,data2),axis=0)\n",
    "\n",
    "images_np = data17\n",
    "\n",
    "#images_np2 = images_np2[:40]\n",
    "\n",
    "print(images_np.shape)\n",
    "\n",
    "num_samples, img_size, canc, channels = images_np.shape\n",
    "\n",
    "fig, axes = plt.subplots(10,9, figsize=(6, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = images_np[i]\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    plt.suptitle(\"Data Images\")\n",
    "    \n",
    "plt.savefig(\"VAEdata.png\", format=\"png\", dpi=600)  # Save as PNG\n",
    "plt.savefig(\"VAEdata.eps\", format=\"eps\")  # Save as PDF\n",
    "plt.savefig(\"VAEdata.pdf\", format=\"pdf\")  # Save as PDF\n",
    "plt.savefig(\"VAEdata.tiff\", format=\"tiff\", dpi=600)  # Save as TIFF\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92dff5-acd0-4cec-80e9-5875d23b4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"VARIATIONAL AUTOENCODER  (FIRST VARIANT)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9b75b-65a0-449a-8822-9f3865c33882",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# --- 1. Define Dataset ---\n",
    "class ArtDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images = images.astype(np.float32)  # Normalize to [-1, 1] if needed\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "# --- 2. Define Variational Autoencoder ---\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, channels=3, latent_dim=128):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # --- Encoder ---\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(channels, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Compute mean and log variance for latent distribution\n",
    "        self.fc_mu = nn.Linear(16 * 16 * 16, latent_dim)  # Map to latent space\n",
    "        self.fc_logvar = nn.Linear(16 * 16 * 16, latent_dim)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 16 * 16 * 16)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Ensure output is in [0,1] range\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick to sample latent vector.\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten dynamically\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder_fc(z).view(-1, 16, 16, 16)\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# --- 3. Training Function ---\n",
    "def train_vae(model, dataloader, epochs=100, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            recon_batch, mu, logvar = model(batch)\n",
    "            \n",
    "            # Reconstruction loss (MSE)\n",
    "            recon_loss = nn.functional.mse_loss(recon_batch, batch, reduction='sum') # #n.L1Loss()  SmoothL1Loss()  BCELoss()  MSELoss() \n",
    "\n",
    "            # KL divergence loss\n",
    "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "            # Total VAE loss\n",
    "            #β < 1 favors better reconstructions. \n",
    "            #β > 1 encourages disentangled latents but can hurt recon quality.\n",
    "            #beta = min(1.0, epoch / 1000.0)  # Linear\n",
    "            beta = 0.5 * (1 - np.cos(np.pi * min(epoch, 1000) / 1000))  # Cosine\n",
    "            loss = recon_loss + beta * kl_loss  \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        print(f\"\\rEpoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\", end=\"\", flush=True)\n",
    "\n",
    "# --- 4. Load and Process Data ---\n",
    "def load_images(image_array, batch_size=32):\n",
    "    dataset = ArtDataset(image_array)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "# --- 5. Testing Function ---\n",
    "def test_vae(model, dataloader, num_images):\n",
    "    model.eval()\n",
    "    images = next(iter(dataloader))[:num_images]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed, _, _ = model(images)\n",
    "\n",
    "    images = images.numpy().transpose(0, 2, 3, 1)\n",
    "    reconstructed = reconstructed.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(12, 5))\n",
    "    for i in range(num_images):\n",
    "        axes[0, i].imshow(images[i])\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(reconstructed[i])\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    axes[0, 0].set_title(\"Original\")\n",
    "    axes[1, 0].set_title(\"Reconstructed\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 6. Random Image Generation ---\n",
    "def generate_random_images(model, num_images=5):\n",
    "    model.eval()\n",
    "    z = torch.randn(num_images, model.latent_dim)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_images = model.decode(z).cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 12))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(generated_images[i])\n",
    "        axes[i].axis('off')\n",
    "    axes[0].set_title(\"Generated Images\")\n",
    "    plt.savefig(\"VAEGenerated_Images.png\", format=\"png\", dpi=600)  # Save as PNG\n",
    "    plt.savefig(\"VAEGenerated_Images.eps\", format=\"eps\")  # Save as PDF\n",
    "    plt.savefig(\"VAEGenerated_Images.pdf\", format=\"pdf\")  # Save as PDF\n",
    "    plt.savefig(\"VAEGenerated_Images.tiff\", format=\"tiff\", dpi=600)  # Save as TIFF\n",
    "    plt.show()\n",
    "\n",
    "# --- 7. Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    # Device configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using device: \" + str(device))\n",
    "    \n",
    "    # Load images from file\n",
    "    #images_np = np.load('Amedeo_Modigliani_faces128x128.npy')\n",
    "    dataloader = load_images(images_np, batch_size=10)\n",
    "\n",
    "    # Create VAE model\n",
    "    vae = VariationalAutoencoder(channels=images_np.shape[-1])\n",
    "\n",
    "    # Train VAE\n",
    "    train_vae(vae, dataloader, epochs=2000, lr=0.002525)\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(vae.state_dict(), 'vae.pth')\n",
    "\n",
    "    # Test VAE\n",
    "    test_vae(vae, dataloader, num_images=10)\n",
    "\n",
    "    # Generate new images\n",
    "    generate_random_images(vae, num_images=10)\n",
    "    \n",
    "      # Generate new images\n",
    "    generate_random_images(vae, num_images=10)\n",
    "    \n",
    "      # Generate new images\n",
    "    generate_random_images(vae, num_images=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Random Image Generation ---\n",
    "def generate_random_images(model, num_images=5):\n",
    "    model.eval()\n",
    "    z = torch.randn(num_images, model.latent_dim)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_images = model.decode(z).cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 16))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(generated_images[i])\n",
    "        axes[i].axis('off')\n",
    "    axes[0].set_title(\"Generated Images\")\n",
    "    plt.savefig(\"VAEGenerated_Images.png\", format=\"png\", dpi=600)  # Save as PNG\n",
    "    plt.savefig(\"VAEGenerated_Images.eps\", format=\"eps\")  # Save as PDF\n",
    "    plt.savefig(\"VAEGenerated_Images.pdf\", format=\"pdf\")  # Save as PDF\n",
    "    plt.savefig(\"VAEGenerated_Images.tiff\", format=\"tiff\", dpi=600)  # Save as TIFF\n",
    "    plt.show()\n",
    "\n",
    "    # Generate new images\n",
    "generate_random_images(vae, num_images=5)\n",
    "\n",
    "    # Generate new images\n",
    "generate_random_images(vae, num_images=5)\n",
    "\n",
    "    # Generate new images\n",
    "generate_random_images(vae, num_images=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6624cb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Transfer image style in latent space \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# --- 1. Define Dataset ---\n",
    "class ArtDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images = images.astype(np.float32)  # Normalize to [-1, 1] if needed\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "# --- 2. Define Variational Autoencoder ---\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, channels=3, latent_dim=128):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # --- Encoder ---\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(channels, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Compute mean and log variance for latent distribution\n",
    "        self.fc_mu = nn.Linear(16 * 16 * 16, latent_dim)  # Map to latent space\n",
    "        self.fc_logvar = nn.Linear(16 * 16 * 16, latent_dim)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 16 * 16 * 16)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Ensure output is in [0,1] range\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick to sample latent vector.\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten dynamically\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder_fc(z).view(-1, 16, 16, 16)\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# --- Load new images and create DataLoader ---\n",
    "def load_new_images(image_file, batch_size=5):\n",
    "    images = np.load(image_file)  # Shape: (10, 128, 128, 3)\n",
    "    dataset = ArtDataset(images)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "# --- Main Function to Process and Plot ---\n",
    "def process_and_plot_vae(vae, new_dataloader, device, num_images=5, alpha=0.5):\n",
    "    vae.eval()\n",
    "    \n",
    "    # Get the new images and move to the correct device\n",
    "    new_images = next(iter(new_dataloader)).to(device)  # Shape: (5, 3, 128, 128)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode new images to latent space\n",
    "        mu, logvar = vae.encode(new_images)\n",
    "        z_new = vae.reparameterize(mu, logvar)  # Latent vectors for new images\n",
    "        \n",
    "        # Generate random latent vectors on the same device\n",
    "        z_random = torch.randn(num_images, vae.latent_dim).to(device)\n",
    "        \n",
    "        # Decode random latent vectors\n",
    "        random_images = vae.decode(z_random)\n",
    "        \n",
    "        # Add latent vectors and decode the result\n",
    "        z_combined = alpha*z_new + (1-alpha)*z_random\n",
    "        combined_images = vae.decode(z_combined)\n",
    "    \n",
    "    # Convert tensors to numpy for plotting (move back to CPU)\n",
    "    new_images_np = new_images.cpu().numpy().transpose(0, 2, 3, 1)  # (5, 128, 128, 3)\n",
    "    random_images_np = random_images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    combined_images_np = combined_images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(num_images * 2, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Original new images\n",
    "        axes[0, i].imshow(new_images_np[i])\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title(\"Original Images\", loc='left')\n",
    "        \n",
    "        # Random generated images\n",
    "        axes[1, i].imshow(random_images_np[i])\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title(\"Random Generated Images\", loc='left')\n",
    "        \n",
    "        # Combined images\n",
    "        axes[2, i].imshow(combined_images_np[i])\n",
    "        axes[2, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[2, i].set_title(\"Combined Latent Space Images\", loc='left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Device configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \" + str(device))\n",
    "\n",
    "    # Load the trained VAE model\n",
    "    vae = VariationalAutoencoder(channels=3, latent_dim=128).to(device)\n",
    "    vae.load_state_dict(torch.load('vae.pth', map_location=device))\n",
    "    \n",
    "    # Load new images to transfer style \n",
    "    new_dataloader = load_new_images('Gabbiano_portrait128x128.npy', batch_size=6) #StillLife128x128.npy\n",
    "    \n",
    "    # Process and plot\n",
    "    process_and_plot_vae(vae, new_dataloader, device, num_images=6, alpha=0.0)\n",
    "    \n",
    "        # Process and plot\n",
    "    process_and_plot_vae(vae, new_dataloader, device, num_images=6, alpha=0.25)\n",
    "    \n",
    "        # Process and plot\n",
    "    process_and_plot_vae(vae, new_dataloader, device, num_images=6, alpha=0.5)\n",
    "    \n",
    "        # Process and plot\n",
    "    process_and_plot_vae(vae, new_dataloader, device, num_images=6, alpha=0.75)\n",
    "    \n",
    "        # Process and plot\n",
    "    process_and_plot_vae(vae, new_dataloader, device, num_images=6, alpha=1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29716b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "        # Process and plot\n",
    "process_and_plot_vae(vae, new_dataloader, device, num_images=6, alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e58422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8869f-aa9f-46e0-9eb0-7dca76f86a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2009d3-c209-48ef-b2a5-e6799786600e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ee94f-5252-4c38-9d3f-9b27398ce289",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"VARIATIONAL AUTOENCODER  (SECOND VARIANT by GROK3)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c50d2-1b9a-4582-9bd2-dd8e3f669602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LOAD IMAGES IN images npy array\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4b48a-554f-41b3-96c2-9b8adcc41825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Piet_Mondrian128x128.npy\n",
    "#Gustav_Klimt128x128.npy\n",
    "#Henri_Matisse128x128.npy \n",
    "#Jackson_Pollock128x128.npy \n",
    "#Pablo_Picasso128x128.npy\n",
    "#Amedeo_Modigliani_faces128x128.npy\n",
    "#Vasiliy_Kandinskiy_geometric128x128.npy\n",
    "#Pablo_Picasso_faces128x128.npy\n",
    "#STUDENT_PHOTOS128x128.npy\n",
    "#Piet_Mondrian_geometric128x128.npy\n",
    "#FinalLightPaintingData128x128.npy\n",
    "    \n",
    "    \n",
    "data1 = np.load('Amedeo_Modigliani_faces128x128.npy')\n",
    "\n",
    "data2 = np.load('Abstractblue.npy') \n",
    "\n",
    "data3 = np.load('Marc_Chagall128x128.npy') \n",
    "\n",
    "data4 = np.load('Monet128x128.npy') \n",
    "\n",
    "data5 = np.load('Henri_de_Toulouse-Lautrec128x128.npy')\n",
    "\n",
    "data6 = np.load('Sidewalk128x128.npy')\n",
    "data7 = np.load('Tunnel128x128.npy') \n",
    "data8 = np.load('Butterfly128x128.npy') \n",
    "\n",
    "data9 = np.load('Amedeo_Modigliani_faces128x128.npy')\n",
    "data10 =np.load('FinalLightPaintingData128x128.npy')\n",
    "\n",
    "data11 = np.load('Sidewalk128x128.npy')\n",
    "data12 = np.load('Tunnel128x128.npy') \n",
    "data13 = np.load('Butterfly128x128.npy') \n",
    "data14 = np.load('Piet_Mondrian_geometric128x128.npy')\n",
    "\n",
    "data15 = np.load('Gabbiano_portrait128x128.npy')\n",
    "\n",
    "data16 = np.load('Gabbiano_Hamiltonian_chaos128x128.npy')\n",
    "\n",
    "data17 = np.load('Gabbiano_portrait128x128.npy')\n",
    "\n",
    "data18 = np.load('Monet paintings.npy') \n",
    "\n",
    "\n",
    "#combine sets\n",
    "#images_np = np.concatenate((data1,data2),axis=0)\n",
    "\n",
    "images = data2\n",
    "\n",
    "#images = images_np2[:40]\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "num_samples, img_size, canc, channels = images.shape\n",
    "\n",
    "fig, axes = plt.subplots(10,9, figsize=(6, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = images[i]\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    plt.suptitle(\"Data Images\")\n",
    "    \n",
    "plt.savefig(\"VAEGrokdata.png\", format=\"png\", dpi=600)  # Save as PNG\n",
    "plt.savefig(\"VAEGrokdata.eps\", format=\"eps\")  # Save as PDF\n",
    "plt.savefig(\"VAEGrokdata.pdf\", format=\"pdf\")  # Save as PDF\n",
    "plt.savefig(\"VAEGrokdata.tiff\", format=\"tiff\", dpi=600)  # Save as TIFF\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6cb2c-ca94-4f1c-af5d-c5de467dd8a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device: \" + str(device))\n",
    "\n",
    "# Assume images is a NumPy array of shape (num, size, size, 3) with values in [0, 1]\n",
    "#images = np.random.rand(1000, 28, 28, 3)  # Example: 1000 RGB images of 28x28, already in [0, 1]\n",
    "num_samples, size, _, channels = images.shape\n",
    "\n",
    "# Convert to PyTorch tensor and reshape to (num_samples, channels, size, size) for PyTorch\n",
    "images = torch.FloatTensor(images).permute(0, 3, 1, 2).to(device)  # Shape: (num_samples, 3, size, size)\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 128  # Size of the latent space\n",
    "hidden_dim = 256  # Size of hidden layers\n",
    "learning_rate = 0.05e-3\n",
    "batch_size = 12\n",
    "num_epochs = 40000\n",
    "\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, hidden_dim, kernel_size=3, stride=2, padding=1),  # Downsample\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Calculate the size after convolutions\n",
    "        conv_output_size = size // 4  # After two strides of 2\n",
    "        conv_output_channels = hidden_dim\n",
    "        self.fc_mu = nn.Linear(hidden_dim * conv_output_size * conv_output_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim * conv_output_size * conv_output_size, latent_dim)\n",
    "        \n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dim * conv_output_size * conv_output_size)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (hidden_dim, conv_output_size, conv_output_size)),\n",
    "            nn.ConvTranspose2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(hidden_dim, input_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Output in [0, 1] since images are in [0, 1]\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder_input(z)\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Loss Function (using Binary Cross-Entropy since images are in [0, 1])\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# Initialize model, optimizer, and data loader\n",
    "model = VAE(input_channels=channels, hidden_dim=hidden_dim, latent_dim=latent_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(images)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training Loop with inline printing\n",
    "train_losses = []\n",
    "\n",
    "print(\"Training...\", end='')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data,) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'\\rEpoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}', end='')\n",
    "\n",
    "print()  # New line after training\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Original vs Decoded Images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Select a few samples for visualization\n",
    "    sample_indices = np.random.choice(num_samples, 4, replace=False)  # Select 4 random images\n",
    "    original_images = images[sample_indices].to(device)\n",
    "    recon_images, _, _ = model(original_images)\n",
    "\n",
    "    original_images = original_images.cpu().numpy().transpose(0, 2, 3, 1)  # Shape: (4, size, size, 3)\n",
    "    recon_images = recon_images.cpu().numpy().transpose(0, 2, 3, 1)  # Shape: (4, size, size, 3)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(4):\n",
    "        # Original Image\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(original_images[i])\n",
    "        plt.title(f'Original {i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Decoded (Reconstructed) Image\n",
    "        plt.subplot(2, 4, i + 5)\n",
    "        plt.imshow(recon_images[i])\n",
    "        plt.title(f'Decoded {i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle('Original vs Decoded Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate New Images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample from latent space\n",
    "    z = torch.randn(16, latent_dim).to(device)  # Generate 16 new samples\n",
    "    generated_images = model.decode(z).cpu().numpy()\n",
    "\n",
    "    # Reshape generated images for plotting\n",
    "    generated_images = generated_images.transpose(0, 2, 3, 1)  # Shape: (16, size, size, 3)\n",
    "\n",
    "    # Plot Generated Samples\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Sample {i+1}')\n",
    "    plt.suptitle('Generated Image Samples')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd55e2a-7d07-47c6-92a6-603fb17060f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save trained VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3e784-6f99-4a2f-9608-4763b9c6d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and optimizer state\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': num_epochs,\n",
    "    'loss': train_losses,\n",
    "}, 'vae_checkpoint.pth')\n",
    "\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a7c21-4eb5-4b70-a306-30741e2f0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Continue training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f7dac-1bdc-4a06-9cbe-fb2a3e434077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Continue Training\n",
    "print(\"\\nLoading checkpoint and continuing training...\", end='')\n",
    "checkpoint = torch.load('vae_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "starting_epoch = checkpoint['epoch']\n",
    "train_losses.extend(checkpoint['loss'])  # Append previous losses\n",
    "\n",
    "# Continue training for additional epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data,) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'\\rEpoch {starting_epoch + epoch + 1}/{starting_epoch + num_epochs} - Loss: {avg_loss:.4f}', end='')\n",
    "\n",
    "print()  # New line after continued training\n",
    "\n",
    "# Plot Training Loss (both initial and additional)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', color='blue')\n",
    "plt.title('Training Loss Over All Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af3cfc-1f93-4998-adfb-19960579afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate New Images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample from latent space\n",
    "    z = torch.randn(25, latent_dim).to(device)  # Generate 16 new samples\n",
    "    generated_images = model.decode(z).cpu().numpy()\n",
    "\n",
    "    # Reshape generated images for plotting\n",
    "    generated_images = generated_images.transpose(0, 2, 3, 1)  # Shape: (16, size, size, 3)\n",
    "\n",
    "    # Plot Generated Samples\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Sample {i+1}')\n",
    "    plt.suptitle('Generated Image Samples')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(\"Generated_Images.png\", format=\"png\", dpi=600)  # Save as PNG\n",
    "    plt.savefig(\"Generated_Images.eps\", format=\"eps\")  # Save as PDF\n",
    "    plt.savefig(\"Generated_Images.pdf\", format=\"pdf\")  # Save as PDF\n",
    "    plt.savefig(\"Generated_Images.tiff\", format=\"tiff\", dpi=600)  # Save as TIFF\n",
    "    plt.show()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b1da3-73ab-4761-a506-cd3d6e17331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"VARIATIONAL AUTOENCODER  (THIRD VARIANT by DEEPSEEK)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e168500-5f84-431a-9cb9-2c05c22895d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LOAD IMAGES\"\"\"\n",
    "\n",
    "#Amedeo_Modigliani_faces128x128.npy\n",
    "#Henri_Matisse128x128.npy\n",
    "#Piet_Mondrian_geometric128x128.npy\n",
    "#Sandro_Botticelli128x128.npy\n",
    "#Vasiliy_Kandinskiy_geometric128x128.npy\n",
    "\n",
    "images = np.load(\"Piet_Mondrian128x128.npy\")\n",
    "\n",
    "#images = images[:200]\n",
    "images.shape\n",
    "\n",
    "print('data loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c98a71-194c-4a3f-961a-79c4a2f3d3b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device: \" + str(device))\n",
    "\n",
    "# Load images from .npy file\n",
    "#images = np.load(\"Amedeo_Modigliani_faces128x128.npy\")  # Shape: (num_samples, size, size, 3)\n",
    "num_samples, size, _, channels = images.shape\n",
    "\n",
    "# Convert to PyTorch tensor and reshape to (num_samples, channels, size, size)\n",
    "images = torch.FloatTensor(images).permute(0, 3, 1, 2).to(device)  # Shape: (num_samples, 3, size, size)\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 2*256  # Size of the latent space\n",
    "hidden_dim = 256  # Size of hidden layers\n",
    "learning_rate = 0.5e-3\n",
    "batch_size = 8\n",
    "num_epochs = 2000\n",
    "\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, hidden_dim, kernel_size=3, stride=2, padding=1),  # Downsample\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Calculate the size after convolutions\n",
    "        conv_output_size = size // 4  # After two strides of 2\n",
    "        conv_output_channels = hidden_dim\n",
    "        self.fc_mu = nn.Linear(hidden_dim * conv_output_size * conv_output_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim * conv_output_size * conv_output_size, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dim * conv_output_size * conv_output_size)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (hidden_dim, conv_output_size, conv_output_size)),\n",
    "            nn.ConvTranspose2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(hidden_dim, input_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Output in [0, 1]\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder_input(z)\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Loss Function (Binary Cross-Entropy + KL Divergence)\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# Initialize model, optimizer, and data loader\n",
    "model = VAE(input_channels=channels, hidden_dim=hidden_dim, latent_dim=latent_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(images, images)  # Use images as both input and target\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training Loop\n",
    "train_losses = []\n",
    "\n",
    "print(\"Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, target, mu, logvar)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'\\rEpoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}',end = \"\")\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Original vs Decoded Images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Select a few samples for visualization\n",
    "    sample_indices = np.random.choice(num_samples, 4, replace=False)  # Select 4 random images\n",
    "    original_images = images[sample_indices].to(device)\n",
    "    recon_images, _, _ = model(original_images)\n",
    "\n",
    "    original_images = original_images.cpu().numpy().transpose(0, 2, 3, 1)  # Shape: (4, size, size, 3)\n",
    "    recon_images = recon_images.cpu().numpy().transpose(0, 2, 3, 1)  # Shape: (4, size, size, 3)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(4):\n",
    "        # Original Image\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(original_images[i])\n",
    "        plt.title(f'Original {i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Decoded (Reconstructed) Image\n",
    "        plt.subplot(2, 4, i + 5)\n",
    "        plt.imshow(recon_images[i])\n",
    "        plt.title(f'Decoded {i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle('Original vs Decoded Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate New Images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Sample from latent space\n",
    "    z = torch.randn(16, latent_dim).to(device)  # Generate 16 new samples\n",
    "    generated_images = model.decode(z).cpu().numpy()\n",
    "\n",
    "    # Reshape generated images for plotting\n",
    "    generated_images = generated_images.transpose(0, 2, 3, 1)  # Shape: (16, size, size, 3)\n",
    "\n",
    "    # Plot Generated Samples\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Sample {i+1}')\n",
    "    plt.suptitle('Generated Image Samples')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfe94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
