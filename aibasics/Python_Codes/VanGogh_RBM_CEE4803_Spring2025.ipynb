{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f977f-243e-45d8-a969-eab86007423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gaussian-Bernoulli RBM for ART IMAGES \n",
    "\n",
    " Art images given in npy arrays\n",
    "\n",
    "VanGogh64x64.npy\n",
    "StillLife64x64.npy\n",
    "Modigliani_paintings.npy\n",
    "Abstractblue.npy\n",
    "\n",
    "#image values are already normalized in [0 1]\n",
    "\n",
    "libraries: \n",
    "\n",
    "!pip install opencv-python tensorflow keras numpy scikit-learn\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dde828-90fe-4fea-bc28-0ececd4d66e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49a81e-3c4c-41c2-918b-8e69d16666ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "load data set and plot a few samples\n",
    "\n",
    "available images\n",
    "\n",
    "VanGogh64x64.npy\n",
    "Monet64x64.npy\n",
    "StillLife64x64.npy\n",
    "Modigliani_paintings.npy\n",
    "AbstractPaintings_Dataset.npy\n",
    "Abstractblue.npy\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de02413-c454-4c8b-ba61-19325d5d918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data already normalized by 255, in the range [0 1]\n",
    "\n",
    "#dataset shape: (num_img, size, size, channels)\n",
    "data = np.load(\"Abstractblue.npy\")\n",
    "\n",
    "num_samples, img_size, canc, channels = data.shape\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = data[i]\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    plt.suptitle(\"Data Images\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "data.shape\n",
    "\n",
    "print(\"data loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4f7a6-4ac7-4e1f-8f2f-7bc99fa9134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RBM needs as input: \n",
    "\n",
    "numpy array filename = data (num_images x size x size x channels) \n",
    "\n",
    "number of hidden neurons (hidden_size) line 161 of the next cell \n",
    "number of epochs (epochs)  line 186 of the next cell \n",
    "learning rate  (hidden_size)\n",
    "batch_size (batch_size)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce73e4-c544-4d00-8f3d-ff02b2eb9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "\n",
    "# Define stable sigmoid function\n",
    "#def sigmoid(x):\n",
    "#    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid(x):\n",
    "    return expit(x)\n",
    "\n",
    "def batch_normalize(v):\n",
    "    mean = np.mean(v, axis=0, keepdims=True)\n",
    "    std = np.std(v, axis=0, keepdims=True) + 1e-8  # Avoid division by zero\n",
    "    return (v - mean) / std\n",
    "    \n",
    "    \n",
    "# Initialize RBM parameters\n",
    "class GaussianBernoulliRBM:\n",
    "    def __init__(self, visible_units, hidden_units, learning_rate, sig):\n",
    "        self.v_units = visible_units\n",
    "        self.h_units = hidden_units\n",
    "        self.lr = learning_rate\n",
    "        self.sigma = sig\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.randn(self.v_units, self.h_units) * 0.01  # Small random values\n",
    "        self.b_v = np.zeros(self.v_units)  # Visible biases\n",
    "        self.b_h = np.zeros(self.h_units)  # Hidden biases\n",
    "\n",
    "    # Forward pass: Sample hidden states given visible states\n",
    "    def sample_hidden(self, v):\n",
    "        h_mean = sigmoid( np.dot(v, self.W)/( (self.sigma) **2 ) + self.b_h )\n",
    "        #h_sample = np.random.binomial(1, h_mean)  # Bernoulli sample\n",
    "        h_sample = (np.random.uniform(size=h_mean.shape) < h_mean).astype(np.float32)\n",
    "        return h_mean, h_sample\n",
    "\n",
    "    # Backward pass: Sample visible states given hidden states\n",
    "    def sample_visible(self, h):\n",
    "        v_mean = np.dot(h, self.W.T) + self.b_v  # Gaussian visible layer\n",
    "        v_sample = v_mean + self.sigma * np.random.randn(*v_mean.shape)  # Add Gaussian noise\n",
    "        return v_mean, v_sample\n",
    "\n",
    "    # Train RBM with Contrastive Divergence (CD-1)\n",
    "    def train(self, data, epochs, batch_size):\n",
    "        num_samples = data.shape[0]\n",
    "        error_list =[]\n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(data)  # Shuffle data each epoch\n",
    "            error = 0\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                v_0 = batch_normalize( data[i:i+batch_size] )  # Mini-batch\n",
    "\n",
    "                # Positive phase\n",
    "                h_0_mean, h_0_sample = self.sample_hidden(v_0)\n",
    "\n",
    "                # Negative phase (Reconstruct visible layer)\n",
    "                v_k_mean, v_k_sample = self.sample_visible(h_0_sample)\n",
    "                h_k_mean, _ = self.sample_hidden(v_k_sample)\n",
    "\n",
    "                # Update weights and biases\n",
    "                self.W += self.lr * (np.dot(v_0.T, h_0_mean) - np.dot(v_k_sample.T, h_k_mean)) / batch_size\n",
    "                self.b_v += self.lr * np.mean(v_0 - v_k_sample, axis=0)\n",
    "                self.b_h += self.lr * np.mean(h_0_mean - h_k_mean, axis=0)\n",
    "\n",
    "                error += np.mean( np.mean( np.abs( v_0 - v_k_mean ), axis=0 ) )\n",
    "\n",
    "            print(f\"\\rEpoch {epoch+1}/{epochs} completed, error={error}\", end=\" \")\n",
    "\n",
    "        error_list.append(error)\n",
    "        return error_list\n",
    "\n",
    "\n",
    "        # Train RBM with Contrastive Divergence (CD-1) + save hidden variables\n",
    "    def train2(self, data, epochs, batch_size):\n",
    "        num_samples = data.shape[0]\n",
    "        error_list = []\n",
    "        hidden_vars_list = []  # Store hidden variables for all images\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(data)  # Shuffle data each epoch\n",
    "            error = 0\n",
    "            hidden_epoch = []  # Store hidden variables for the current epoch\n",
    "    \n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                v_0 = data[i:i+batch_size]  # Mini-batch\n",
    "    \n",
    "                # Positive phase\n",
    "                h_0_mean, h_0_sample = self.sample_hidden(v_0)\n",
    "    \n",
    "                # Store hidden representations\n",
    "                hidden_epoch.append(h_0_mean)\n",
    "    \n",
    "                # Negative phase (Reconstruct visible layer)\n",
    "                v_k_mean, v_k_sample = self.sample_visible(h_0_sample)\n",
    "                h_k_mean, _ = self.sample_hidden(v_k_sample)\n",
    "    \n",
    "                # Update weights and biases\n",
    "                self.W += self.lr * (np.dot(v_0.T, h_0_mean) - np.dot(v_k_sample.T, h_k_mean)) / batch_size\n",
    "                self.b_v += self.lr * np.mean(v_0 - v_k_sample, axis=0)\n",
    "                self.b_h += self.lr * np.mean(h_0_mean - h_k_mean, axis=0)\n",
    "    \n",
    "                error += np.mean(np.mean(np.abs(v_0 - v_k_mean), axis=0))\n",
    "    \n",
    "            print(f\"\\rEpoch {epoch+1}/{epochs} completed, error={error}\", end=\" \")\n",
    "    \n",
    "            error_list.append(error)\n",
    "            hidden_vars_list.append(np.vstack(hidden_epoch))  # Stack batch results\n",
    "    \n",
    "                # Select three dimensions to visualize\n",
    "        n1, n2, n3 = 0, 1, 2  # Change these indices based on your preference\n",
    "        hidden_vars_array = np.array(hidden_vars_list)\n",
    "        # Extract the selected dimensions\n",
    "        x = hidden_vars_array[:, n1]\n",
    "        y = hidden_vars_array[:, n2]\n",
    "        z = hidden_vars_array[:, n3]\n",
    "        \n",
    "        # 3D Plot\n",
    "        fig = plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.scatter(x, y, z, c='b', marker='o', alpha=0.6)\n",
    "        ax1.set_xlabel(f'Hidden Variable {n1}')\n",
    "        ax1.set_ylabel(f'Hidden Variable {n2}')\n",
    "        ax1.set_zlabel(f'Hidden Variable {n3}')\n",
    "        ax1.set_title('3D Scatter Plot of Hidden Variables')\n",
    "        \n",
    "        # 2D Plot (n1 vs. n2)\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.scatter(x, y, c='r', alpha=0.6)\n",
    "        ax2.set_xlabel(f'Hidden Variable {n1}')\n",
    "        ax2.set_ylabel(f'Hidden Variable {n2}')\n",
    "        ax2.set_title('2D Scatter Plot of Hidden Variables')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return error_list, np.vstack(hidden_vars_list)  # Return hidden variables for all images\n",
    "    \n",
    "    \n",
    "    # Generate samples from the trained RBM\n",
    "    def generate_samples(self, num_samples, steps):\n",
    "        v = np.random.randn(num_samples, self.v_units)  # Random initialization\n",
    "\n",
    "        for _ in range(steps):  # Gibbs Sampling\n",
    "            h_mean, h_sample = self.sample_hidden(v)\n",
    "            v_mean, v = self.sample_visible(h_sample)\n",
    "\n",
    "        return v_mean, h_mean # Return final generated visible samples and hidden variables \n",
    "\n",
    "\"\"\"\n",
    "# main \n",
    "#data = np.load(\"VanGogh.npy\")\n",
    "#dataset shape:(855, 64, 64, 3)\n",
    "#data already normalized by 255, in the range [0 1]\n",
    "\"\"\"\n",
    "\n",
    "num_samples, img_size, canc, channels = data.shape\n",
    "hidden_size = 32  # number of hidden variables \n",
    "\n",
    "data_flat = data.reshape(num_samples, -1) #Array  num_samples x img_size^2\n",
    "\n",
    "# Normalize images to [-1,1] for Gaussian-Bernoulli RBM\n",
    "data_flat = (data_flat - 0.5) * 2  \n",
    "\n",
    "fig, axes = plt.subplots(1, 8, figsize=(10, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    img = data[i].reshape(img_size, img_size, channels)\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    plt.suptitle(\"Data Samples\")\n",
    "\n",
    "plt.savefig(\"DataSamples.png\", format=\"png\", dpi=300)  # Save as PNG\n",
    "plt.savefig(\"DataSamples.eps\", format=\"eps\")  # Save as PDF\n",
    "plt.savefig(\"DataSamples.pdf\", format=\"pdf\")  # Save as PDF\n",
    "plt.savefig(\"DataSamples.tiff\", format=\"tiff\", dpi=300)  # Save as TIFF\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"start training\")\n",
    "# Train RBM on CBL Faces\n",
    "rbm = GaussianBernoulliRBM(visible_units=channels*img_size**2, hidden_units=hidden_size, learning_rate=0.025, sig=0.1)\n",
    "rbm.train2(data_flat, epochs=1000, batch_size=16)\n",
    "\n",
    "# Generate and plot new face samples\n",
    "generated_data, generated_hidden_var= rbm.generate_samples(num_samples=25, steps=100)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = generated_data[i].reshape(img_size, img_size, channels)\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "    ax.imshow(img, cmap='winter')\n",
    "    ax.axis(\"off\")\n",
    "    plt.suptitle(\"Generated Samples\")  \n",
    "\n",
    "plt.savefig(\"GeneratedSamples.png\", format=\"png\", dpi=300)  # Save as PNG\n",
    "plt.savefig(\"GeneratedSamples.eps\", format=\"eps\")  # Save as PDF\n",
    "plt.savefig(\"GeneratedSamples.pdf\", format=\"pdf\")  # Save as PDF\n",
    "plt.savefig(\"GeneratedSamples.tiff\", format=\"tiff\", dpi=300)  # Save as TIFF\n",
    "\n",
    "plt.show()\n",
    "\n",
    "hidden_n = int(np.sqrt(hidden_size)) \n",
    "# Plot weight columns as images (Visualizing hidden features)\n",
    "fig, axes = plt.subplots(hidden_n, hidden_n, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < rbm.h_units:\n",
    "        img = rbm.W[:, i].reshape(img_size, img_size, channels)\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "        ax.imshow(img, cmap='winter')\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Weight Columns as Images (Hidden Features)\")\n",
    "\n",
    "plt.savefig(\"WeightColumnsasImages.png\", format=\"png\", dpi=300)  # Save as PNG\n",
    "plt.savefig(\"WeightColumnsasImages.eps\", format=\"eps\")  # Save as PDF\n",
    "plt.savefig(\"WeightColumnsasImages.pdf\", format=\"pdf\")  # Save as PDF\n",
    "plt.savefig(\"WeightColumnsasImages.tiff\", format=\"tiff\", dpi=300)  # Save as TIFF\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf587fa-09a8-48de-91fc-c880ce3e8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b976ebb-5e6f-40d8-8bf9-266e1d434c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PLOT PROBABILITY DENSITY FUNCTION OF DATA\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398c651-6b75-421a-a244-07daf3f2387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume x_train is (400, 32, 32)\n",
    "x1= data_flat.reshape(-1)  # Flatten all pixels into 1D\n",
    "\n",
    "# Compute histogram (PDF estimation)\n",
    "hist, bins = np.histogram(x1, bins=30, density=True)\n",
    "\n",
    "# Compute bin centers\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "# Plot empirical PDF\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(bin_centers, hist, linestyle='-', marker='o', label=\"Empirical PDF\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Empirical PDF of Pixel Intensities\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718f630-8696-4792-ad62-53b5238f31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and plot new samples\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe5bdac-b8ea-4fe3-8623-59f20671e19d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate and plot new face samples\n",
    "generated_faces, generated_hidden_var= rbm.generate_samples(num_samples=100, steps=20)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(7, 7))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = generated_faces[i].reshape(img_size, img_size, channels)\n",
    "    img =  (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "    ax.imshow(img, cmap='winter')\n",
    "    ax.axis(\"off\")\n",
    "    plt.suptitle(\"Generated Samples\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d756d-ee4a-4404-aa87-c6e81d8d8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot weight columns as images (Visualizing hidden features)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072009fc-e74a-4fca-aad3-03ecd4482c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot weight columns as images (Visualizing hidden features)\n",
    "fig, axes = plt.subplots(5, 5, figsize=(7, 7))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < rbm.h_units:\n",
    "        img = rbm.W[:, i].reshape(img_size, img_size, channels)\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # Normalize for visualization\n",
    "        ax.imshow(img, cmap='winter')\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Weight Columns as Images (Hidden Features)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49c2bc-abcc-4793-9051-7142286a36e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24577346-e1de-42d9-8ff4-8b8f512b977f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6afe29-f49d-4d8e-b687-d23b316b5b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa698177-f3e2-48a3-b9cd-be2c4caa250b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
